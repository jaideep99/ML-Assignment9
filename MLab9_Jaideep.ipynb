{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLab9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1DjcuJo03ajUPAqWvAdnQXI-YQFrhHctB",
      "authorship_tag": "ABX9TyPN0IV4FDNxN8lerCiXu3PO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaideep99/ML-Assignment9/blob/master/MLab9_Jaideep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_zR4lsT0JzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ9kWPvDO9fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "bee1dadc-5c17-4e10-ed60-2476a14e40b3"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/mnist_train (1).csv',header=None)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>252</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  778  779  780  781  782  783  784\n",
              "0    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    5\n",
              "1    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "2    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    4\n",
              "3    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
              "4    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    9\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cisje13VPRsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2209626d-01d3-4af7-e412-4df503c1f05f"
      },
      "source": [
        "print(data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6vQSgibPVP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(data.drop([784],axis=1),data[784],test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcTnupDUQ_o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = pd.get_dummies(y_train).values\n",
        "y_test = pd.get_dummies(y_test).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0D-bMI3QgbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "51a3aeba-e172-4274-f658-0414a760eb0c"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 784)\n",
            "(8000, 10)\n",
            "(2000, 784)\n",
            "(2000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JmnfgPMD9k",
        "colab_type": "text"
      },
      "source": [
        "###Zero Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6tuJ-lWWQbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x)/sum(np.exp(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly_nuyMoRJ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_weights_perceptron(X, Y, W, b, lr):\n",
        "  m = 784\n",
        "  Yp = sigmoid(np.dot(X,W)+b)\n",
        "  dE = (Y-Yp)\n",
        "  dW = (1/m)*X.T.dot(dE)\n",
        "  db = np.sum(dE)\n",
        "  W = W+(dW*lr)\n",
        "  b = b+(db*lr)\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uh61tDwVLne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c3bbb318-b93a-4cb6-d8dc-cbc3e02e62da"
      },
      "source": [
        "W = np.random.randn(784,10)\n",
        "b = np.random.randn(10)\n",
        "\n",
        "epochs = 100\n",
        "for i in range(epochs):\n",
        "  W,b = update_weights_perceptron(x_train,y_train,W,b,0.01)\n",
        "\n",
        "pred = sigmoid(np.dot(x_train,W)+b)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVdGC1oHWLei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d6aca34-19c8-4757-e7a5-35490d56593c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "p = np.argmax(pred,axis=1)\n",
        "t = np.argmax(y_train,axis=1)\n",
        "print(accuracy_score(t,p)*100)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJTcK-S5JpAV",
        "colab_type": "text"
      },
      "source": [
        "###One Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCQdkECl7Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_weights_percept(X, Y, W, b, lr):\n",
        "\n",
        "  A = sigmoid(np.dot(X,W[0])+b[0])\n",
        "  Yp= sigmoid(np.dot(A,W[1])+b[1])\n",
        "\n",
        "  dW2 = (Y-Yp)\n",
        "  dW1 = dW2.dot(W[1].T)\n",
        "  \n",
        "  db2 = np.sum(dW2)\n",
        "  db1 = db2*(b[1])\n",
        "\n",
        "  W2 = W[1]+(A.T.dot(dW2)*lr)\n",
        "  W1 = W[0]+(X.T.dot(dW1)*lr)\n",
        "  \n",
        "  b2 = b[1]+(db2*lr)\n",
        "  b1 = b[0]+(db1*lr)\n",
        "  return W1,W2,b1,b2\n",
        "\n",
        "def model(N,x_train,y_train):\n",
        "  W1 = np.random.randn(784,N)\n",
        "  b1 = np.random.randn(N)\n",
        "  W2 = np.random.randn(N,10)\n",
        "  b2 = np.random.randn(10)\n",
        "\n",
        "  W = [W1,W2]\n",
        "  b = [b1,b2]\n",
        "  epochs = 1000\n",
        "  for i in range(epochs):\n",
        "    W[0],W[1],b[0],b[1] = update_weights_percept(x_train,y_train,W,b,0.001)\n",
        "\n",
        "  A = sigmoid(np.dot(x_train,W[0])+b[0])\n",
        "  Yp= sigmoid(np.dot(A,W[1])+b[1])\n",
        "\n",
        "  pred = Yp\n",
        "\n",
        "  p = np.argmax(pred,axis=1)\n",
        "  t = np.argmax(y_train,axis=1)\n",
        "  print(\"accuracy : \",accuracy_score(t,p)*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q64v7gERpCpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "48b5e1a8-9f4b-4983-85f7-fe8a3afad4b8"
      },
      "source": [
        "model(10,x_train,y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLQlrhZUJsqd",
        "colab_type": "text"
      },
      "source": [
        "###Double Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYrUxX46Bge1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_weights_percept_double(X, Y, W, b, lr):\n",
        "\n",
        "  A = sigmoid(np.dot(X,W[0])+b[0])\n",
        "  B = sigmoid(np.dot(A,W[1])+b[1])\n",
        "  Yp= sigmoid(np.dot(B,W[2])+b[2])\n",
        "\n",
        "  dW3 = (Y-Yp)\n",
        "  dW2 = dW3.dot(W[2].T)\n",
        "  dW1 = dW2.dot(W[1].T)\n",
        "  \n",
        "  db3 = np.sum(dW3)\n",
        "  db2 = np.sum(db3*(b[1]))\n",
        "  db1 = np.sum(db2*(b[0]))\n",
        "\n",
        "  W3 = W[2]+(B.T.dot(dW3)*lr)\n",
        "  W2 = W[1]+(A.T.dot(dW2)*lr)\n",
        "  W1 = W[0]+(X.T.dot(dW1)*lr)\n",
        "  \n",
        "  b3 = b[2]+(db3*lr)\n",
        "  b2 = b[1]+(db2*lr)\n",
        "  b1 = b[0]+(db1*lr)\n",
        "  return W1,W2,W3,b1,b2,b3\n",
        "\n",
        "def model(N,x_train,y_train):\n",
        "  W1 = np.random.randn(784,N)\n",
        "  b1 = np.random.randn(N)\n",
        "  W2 = np.random.randn(N,N)\n",
        "  b2 = np.random.randn(N)\n",
        "  W3 = np.random.randn(N,10)\n",
        "  b3 = np.random.randn(10)\n",
        "\n",
        "  W = [W1,W2,W3]\n",
        "  b = [b1,b2,b3]\n",
        "  epochs = 100\n",
        "  for i in range(epochs):\n",
        "    W[0],W[1],W[2],b[0],b[1],b[2] = update_weights_percept_double(x_train,y_train,W,b,0.001)\n",
        "\n",
        "  A = sigmoid(np.dot(x_train,W[0])+b[0])\n",
        "  B = sigmoid(np.dot(A,W[1])+b[1])\n",
        "  Yp= sigmoid(np.dot(B,W[2])+b[2])\n",
        "\n",
        "  pred = Yp\n",
        "\n",
        "  p = np.argmax(pred,axis=1)\n",
        "  t = np.argmax(y_train,axis=1)\n",
        "  print(accuracy_score(t,p)*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKrT5QkQDSjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "fe825171-5319-4dab-b7f5-12a7003521b0"
      },
      "source": [
        "model(10,x_train,y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in multiply\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in add\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGtTKbhJxMK",
        "colab_type": "text"
      },
      "source": [
        "###SGD Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3yc6mayfEx5s",
        "colab": {}
      },
      "source": [
        "def update_weights_momentum(X, Y, W, b, lr,beta,i,V):\n",
        "\n",
        "  m = 784\n",
        "  Yp = sigmoid(np.dot(X,W)+b)\n",
        "\n",
        "  #weight gradients\n",
        "  dE = (Y-Yp)\n",
        "  dW = (1/m)*X.T.dot(dE)\n",
        "  db = np.sum(dE)\n",
        "  \n",
        "  #Average of exponential weighted gradients\n",
        "  if(i==0):\n",
        "    V = dW*lr\n",
        "  else:\n",
        "    V = beta*V+(dW*lr)\n",
        "\n",
        "  W = W+V\n",
        "  b = b+db\n",
        "\n",
        "  return W,b,V"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6ebcb38d-b47f-42cd-ab6a-95508061190f",
        "id": "ixmBMUG9Ex5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "W = np.random.randn(784,10)\n",
        "b = np.random.randn(10)\n",
        "\n",
        "#co-efficient of momentum\n",
        "epochs = 100\n",
        "\n",
        "beta = 0.9\n",
        "\n",
        "V = []\n",
        "for i in range(epochs):\n",
        "  W,b,V = update_weights_momentum(x_train,y_train,W,b,0.01,beta,i,V)\n",
        "\n",
        "pred = sigmoid(np.dot(x_train,W)+b)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d7a7db3-517b-40de-d007-a87671c26b84",
        "id": "Q3rL3wCxEx55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = np.argmax(pred,axis=1)\n",
        "t = np.argmax(y_train,axis=1)\n",
        "print(\"accuracy : \",accuracy_score(t,p)*100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy :  84.5875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-p2oe6eMMaT",
        "colab_type": "text"
      },
      "source": [
        "###Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R4yyOIPtMK33",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "\n",
        "def update_weights_perceptron(X, Y, W, b, lr,activation):\n",
        "  m = 784\n",
        "  if(activation=='relu'):\n",
        "    Yp = relu(np.dot(X,W)+b)\n",
        "    dE = (Y-Yp)*reluDerivative(Yp)\n",
        "    dW = (1/m)*X.T.dot(dE)\n",
        "    db = np.sum(dE)\n",
        "  elif(activation=='sigmoid'):\n",
        "    Yp = sigmoid(np.dot(X,W)+b)\n",
        "    dE = (Y-Yp)\n",
        "    dW = (1/m)*X.T.dot(dE)\n",
        "    db = np.sum(dE)\n",
        "  elif(activation=='tanh'):\n",
        "    Yp = tanh(np.dot(X,W)+b)\n",
        "    dE = (Y-Yp)\n",
        "    dW = (1/m)*X.T.dot(dE)\n",
        "    db = np.sum(dE)\n",
        "\n",
        "  elif(activation=='softmax'):\n",
        "    Yp = softmax(np.dot(X,W)+b)\n",
        "    dE = (Y-Yp)\n",
        "    dW = (1/m)*X.T.dot(dE)\n",
        "    db = np.sum(dE)\n",
        "\n",
        "  W = W+(dW*lr)\n",
        "  b = b+(db*lr)\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f7daca2-d8ea-4867-a7be-59ae696173d2",
        "id": "82df4gupMK38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "W = np.random.randn(784,10)\n",
        "b = np.random.randn(10)\n",
        "\n",
        "epochs = 100\n",
        "for i in range(epochs):\n",
        "  W,b = update_weights_perceptron(x_train,y_train,W,b,0.01,'sigmoid')\n",
        "\n",
        "pred = sigmoid(np.dot(x_train,W)+b)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c4b51b4e-9547-48cb-8169-2d16e40f9d82",
        "id": "Px7CRexNMK4B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = np.argmax(pred,axis=1)\n",
        "t = np.argmax(y_train,axis=1)\n",
        "print(\"accuracy score : \",accuracy_score(t,p)*100)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score :  82.8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}